{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "df = pd.read_csv('./content/results/cars_v1.csv')\n",
    "df_cols = ['name', 'model', 'year', 'color', 'fuelType', 'carOrigin', 'carInsurance', 'gearType', 'mirrorType', 'motorPower', 'drivenKm', 'passengers', 'paymentMethod', 'saleType', 'secondHandStatus','price']\n",
    "numeric_cols = ['year', 'motorPower', 'drivenKm', 'passengers', 'secondHandStatus','price']\n",
    "cats_min = ['fuelType', 'carOrigin', 'carInsurance', 'gearType', 'mirrorType', 'paymentMethod', 'saleType']\n",
    "cats_top = ['name', 'model', 'color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Engineering & Selection ##\n",
    "scaler = MinMaxScaler()\n",
    "fh = FeatureHasher(n_features=6, input_type='string')\n",
    "dumms_df = pd.get_dummies(df[cats_min], columns=cats_min)\n",
    "\n",
    "# # including only numeric columns\n",
    "# ndf = df[numeric_cols]\n",
    "# # ndf = pd.DataFrame(scaler.fit_transform(ndf), columns=ndf.columns) # scaling numeric columns\n",
    "\n",
    "# # encoding categorical data\n",
    "num_df = df[numeric_cols]\n",
    "# num_df = pd.DataFrame(scaler.fit_transform(num_df), columns=num_df.columns) # scaling numeric columns\n",
    "hashed_df = fh.fit_transform(df[cats_top].astype(str).values)\n",
    "hashed_df = pd.DataFrame(hashed_df.toarray(), columns=['name_1', 'name_2', 'name_3', 'name_4', 'name_5', 'name_6'])\n",
    "ndf = pd.concat([num_df, dumms_df,hashed_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Dataframe with dropping all rows with NaN values\n",
    "naDF = ndf.dropna()\n",
    "\n",
    "# removing outliers - naDF\n",
    "Q1 = naDF.quantile(0.25, numeric_only=True)\n",
    "Q3 = naDF.quantile(0.75, numeric_only=True)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "naDF = naDF[~((naDF < (Q1 - 1.5 * IQR)) | (naDF > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "# 2- Dataframe with filling all NaN values with fillna (mode) method\n",
    "fnDF = ndf.copy()\n",
    "for column in fnDF.columns:\n",
    "  fnDF[column].fillna(fnDF[column].mode()[0], inplace=True)\n",
    "\n",
    "# removing outliers - fnDF\n",
    "Q1 = fnDF.quantile(0.25, numeric_only=True)\n",
    "Q3 = fnDF.quantile(0.75, numeric_only=True)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "fnDF = fnDF[~((fnDF < (Q1 - 1.5 * IQR)) | (fnDF > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: 0.7137615790241527\n",
      "Decision Tree: 0.6069517890190514\n",
      "KNN: 0.18917770776432175\n"
     ]
    }
   ],
   "source": [
    "# using models: linear regression, tree regressor, random forest, KNN\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "trainDF = naDF.copy()\n",
    "y = trainDF['price']\n",
    "trainDF = trainDF.drop(columns=['price'])\n",
    "X = trainDF\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=33143121)\n",
    "\n",
    "## Linear Regression\n",
    "# lr = LinearRegression()\n",
    "lr = Ridge(alpha=1.0)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(f\"Linear Regression: {lr.score(X_test, y_test)}\")\n",
    "\n",
    "## Decision Tree Regressor\n",
    "dt = DecisionTreeRegressor(random_state=0, max_depth=5)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(f\"Decision Tree: {dt.score(X_test, y_test)}\")\n",
    "\n",
    "## KNN model\n",
    "knn = KNeighborsRegressor(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(f\"KNN: {knn.score(X_test, y_test)}\")\n",
    "\n",
    "# ## Random Forest Classifier - Only works for classification problems\n",
    "# rf = RandomForestClassifier(n_estimators=100)\n",
    "# rf.fit(X_train, y_train)\n",
    "# y_pred = rf.predict(X_test)\n",
    "# print(F\"Random Forest: {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model and loading it\n",
    "import pickle\n",
    "pickle.dump(lr, open('./app/models/model_v2.pkl', 'wb'))\n",
    "\n",
    "# model = pickle.load(open('./app/models/model_v1.pkl', 'rb'))\n",
    "# print(model.predict([[2000, 5000, 70000, 4, 1]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
